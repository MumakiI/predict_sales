{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import gc\n",
    "import tqdm.notebook as tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data, train_size):\n",
    "    return all_data.loc[:train_size-1], all_data.loc[train_size:].drop(['target'], axis=1)\n",
    "\n",
    "def get_result_df(predict, round=False):\n",
    "    result = pd.DataFrame(data={'ID': range(0, 214200), 'item_cnt_month': predict})\n",
    "#     clip after aggregation?\n",
    "    result['item_cnt_month'] = result['item_cnt_month'].clip(0, 20)\n",
    "    if round:\n",
    "        result['item_cnt_month'] = result['item_cnt_month'].round()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('sales_train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_shops = pd.read_csv('shops.csv')\n",
    "df_items = pd.read_csv('items.csv')\n",
    "df_item_cats = pd.read_csv('item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX SHOPS\n",
    "\n",
    "# Якутск Орджоникидзе, 56\n",
    "df_train.loc[df_train.shop_id == 0, 'shop_id'] = 57\n",
    "df_test.loc[df_test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "df_train.loc[df_train.shop_id == 1, 'shop_id'] = 58\n",
    "df_test.loc[df_test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "df_train.loc[df_train.shop_id == 10, 'shop_id'] = 11\n",
    "df_test.loc[df_test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cats from shops\n",
    "\n",
    "# Extract type and sub type code\n",
    "df_item_cats['split'] = df_item_cats['item_category_name'].str.split('-')\n",
    "df_item_cats['type'] = df_item_cats['split'].map(lambda x: x[0].strip())\n",
    "df_item_cats['type_code'] = LabelEncoder().fit_transform(df_item_cats['type'])\n",
    "# if subtype is nan then type\n",
    "df_item_cats['subtype'] = df_item_cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "df_item_cats['subtype_code'] = LabelEncoder().fit_transform(df_item_cats['subtype'])\n",
    "df_item_cats = df_item_cats[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "# Extract city\n",
    "df_shops.loc[df_shops['shop_name'] == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "df_shops['city'] = df_shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "df_shops.loc[df_shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "df_shops['city_code'] = LabelEncoder().fit_transform(df_shops['city'])\n",
    "df_shops = df_shops[['shop_id','city_code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify wether train and test data from same distribution \n",
    "df_train_unique_shop_item = df_train[['shop_id', 'item_id']].drop_duplicates()\n",
    "df_train_unique_shop_item['count'] = 1\n",
    "matched_pair_count = pd.merge(df_test, df_train_unique_shop_item, on=['shop_id', 'item_id'], how='left')['count'].sum()\n",
    "\n",
    "same_distribution = df_test.shape[0] == matched_pair_count\n",
    "fraction_of_misshig = round(1 - matched_pair_count/df_test.shape[0], 2)\n",
    "print(f'Test and traind data are from same distribution: {same_distribution}')\n",
    "print(f'Fraction of test data missing in train data: {fraction_of_misshig}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare mean encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10913850\n",
      "214200\n",
      "11128050\n",
      "11128050\n"
     ]
    }
   ],
   "source": [
    "sales = df_train.copy()\n",
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'})\n",
    "gb['item_cnt_day'] = gb['item_cnt_day'].clip(0, 20)\n",
    "gb.rename(columns={'item_cnt_day': 'target'}, inplace=True)\n",
    "\n",
    "# Fix column names\n",
    "#gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "gb['item_cnt_day'] = gb['item_cnt_day'].clip(0, 20)\n",
    "gb.rename(columns={'item_cnt_day': 'target_shop'}, inplace=True)\n",
    "#gb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "gb['item_cnt_day'] = gb['item_cnt_day'].clip(0, 20)\n",
    "gb.rename(columns={'item_cnt_day': 'target_item'}, inplace=True)\n",
    "#gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "\n",
    "TRAIN_SIZE = all_data.shape[0]\n",
    "\n",
    "df_test_concat = df_test.drop(columns=['ID'])\n",
    "df_test_concat['date_block_num'] = 34\n",
    "all_data = concat_df(all_data, df_test_concat)\n",
    "\n",
    "print(TRAIN_SIZE)\n",
    "print(df_test_concat.shape[0])\n",
    "print(TRAIN_SIZE + df_test_concat.shape[0])\n",
    "print(len(df_all))\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb, df_test_concat, sales\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare historical lags item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63c9696dd174158a2f1664f9fab7d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in tqdm.tqdm(shift_range):\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "del train_shift\n",
    "\n",
    "\n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = df_items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = pd.merge(all_data, df_item_cats, how='left', on='item_category_id')\n",
    "all_data = pd.merge(all_data, df_shops, how='left', on='shop_id')\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11128050, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10913850\n",
      "214200\n",
      "11128050\n"
     ]
    }
   ],
   "source": [
    "# WHAT THE FUCK MAN???\n",
    "# df_model = pd.merge(df_all, all_data, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "# df_model['shop_id'] = df_model['shop_id'].astype('category')\n",
    "# df_model['item_category_id'] = df_model['item_category_id'].astype('category')\n",
    "# df_model = pd.get_dummies(df_model, drop_first=True)\n",
    "\n",
    "target_col = 'target'\n",
    "train, X_test = divide_df(all_data, TRAIN_SIZE)\n",
    "\n",
    "print(train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "print(train.shape[0] + X_test.shape[0])\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "train = train[train['date_block_num'] >= 12] \n",
    "\n",
    "X_train = train.drop(columns=[target_col])\n",
    "Y_train = train[target_col]\n",
    "\n",
    "del train, df_all, all_data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "cv_fraction = 1\n",
    "item_set = X_train['item_id'].unique()\n",
    "random.shuffle(item_set)\n",
    "l = int(len(item_set) * cv_fraction)\n",
    "cv_item_set = item_set[:l]\n",
    "cv_items_filter = X_train['item_id'].isin(cv_item_set)\n",
    "\n",
    "cv_X_train = X_train[cv_items_filter]\n",
    "cv_Y_train = Y_train[cv_items_filter]\n",
    "\n",
    "max_date = cv_X_train['date_block_num'].max()\n",
    "\n",
    "cv_X_test = cv_X_train[cv_X_train['date_block_num'] == max_date]\n",
    "cv_Y_test = cv_Y_train[cv_X_train['date_block_num'] == max_date]\n",
    "\n",
    "cv_Y_train = cv_Y_train[cv_X_train['date_block_num'] < max_date]\n",
    "cv_X_train = cv_X_train[cv_X_train['date_block_num'] < max_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238172"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HP optimization and prediction with lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_lgbm(X, Y, X_val, Y_val, X_test, params = None):\n",
    "    from scipy.stats import randint as sp_randint\n",
    "    from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "    if not params:\n",
    "#         lgb_params = {\n",
    "#                        'feature_fraction': [0.55, 0.65, 0.75, 0.85, 0.95],\n",
    "#                        'metric': ['rmse'],\n",
    "#                        'nthread':[-1], \n",
    "#                        'min_data_in_leaf': [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10], \n",
    "#                        'bagging_fraction': [0.65, 0.75, 0.85], \n",
    "#                        'learning_rate': [0.1, 0.01, 0.03], \n",
    "#                        'objective': ['mse'], \n",
    "#                        'bagging_seed': [2**7], \n",
    "#                        'num_leaves': sp_randint(100, 1000),\n",
    "#                        'bagging_freq':[1],\n",
    "#                        'verbose':[0] \n",
    "#                       }\n",
    "        lgb_params ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "        fit_params={\"early_stopping_rounds\":30, \n",
    "                    \"eval_metric\" : 'rmse', \n",
    "                    \"eval_set\" : [(X_val, Y_val)],\n",
    "                    'eval_names': ['valid'],\n",
    "                    #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "                    'verbose': 100,\n",
    "                    'categorical_feature': 'auto'}\n",
    "        \n",
    "        n_HP_points_to_test = 10\n",
    "        \n",
    "        clf = lgb.LGBMRegressor(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=10)\n",
    "        gs = RandomizedSearchCV(\n",
    "            estimator=clf, param_distributions=lgb_params, \n",
    "            n_iter=n_HP_points_to_test,\n",
    "            scoring='r2',\n",
    "            cv=4,\n",
    "            refit=True,\n",
    "            random_state=314,\n",
    "            verbose=False)\n",
    "        gs.fit(X, Y, **fit_params)\n",
    "        print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))\n",
    "        params = gs.best_params_\n",
    "    \n",
    "#     lgb_params = {\n",
    "#                'feature_fraction': params['feature_fraction'],\n",
    "#                'metric': params['metric'],\n",
    "#                'nthread': params['nthread'], \n",
    "#                'min_data_in_leaf': params['min_data_in_leaf'], \n",
    "#                'bagging_fraction': params['bagging_fraction'], \n",
    "#                'learning_rate': params['learning_rate'], \n",
    "#                'objective': params['objective'], \n",
    "#                'bagging_seed': params['bagging_seed'], \n",
    "#                'num_leaves': params['num_leaves'],\n",
    "#                'bagging_freq':params['bagging_freq'],\n",
    "#                'verbose':params['verbose'] \n",
    "#               }\n",
    "\n",
    "    model = lgb.train(params, lgb.Dataset(X, label=Y), 100)\n",
    "    pred_lgb = model.predict(X_test)\n",
    "    return pred_lgb, params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_result_df(Y_predict1, round=True).to_csv('result_rfc_26_features_round.csv', index=False)\n",
    "# Nice, but the solution can be improved! Your public and private LB scores are: 1.107601 and 1.105683."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_lr(X, Y, X_test):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X.values, Y)\n",
    "    pred_lr = lr.predict(X_test.values)\n",
    "    return pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix(alpha, X):\n",
    "    return (alpha * X[:,0]) + ((1-alpha) * X[:,1])\n",
    "\n",
    "def get_best_alpha(X_train_level2, target):\n",
    "    alphas_to_try = np.linspace(0, 1, 1001)\n",
    "    max_r2 = 0\n",
    "    best_alpha = 1\n",
    "    \n",
    "    for alpha in alphas_to_try:\n",
    "        mix = get_mix(alpha, X_train_level2)\n",
    "        r2 = r2_score(target, mix)\n",
    "        if max_r2 < r2:\n",
    "            max_r2 = r2\n",
    "            best_alpha = alpha\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 27)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.931902\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.937028\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.934138\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.932592\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.9295\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.930752\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.929825\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.925854\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.954076\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.956078\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.956452\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.952938\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.929884\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.935509\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.933417\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.929786\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.935104\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.935892\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.935759\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.931928\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.955843\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.959235\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.959313\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.957148\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.925566\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.926498\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.926963\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.920767\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.937167\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.936405\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.938557\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.93584\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.946316\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.950055\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.949163\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.945846\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.932264\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.938265\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.937725\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.934313\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 0.921099\n",
      "Best score reached: 0.4178436670271215 with params: {'colsample_bytree': 0.8754369812451743, 'min_child_samples': 372, 'min_child_weight': 10.0, 'num_leaves': 44, 'reg_alpha': 1, 'reg_lambda': 0, 'subsample': 0.568664015245299} \n"
     ]
    }
   ],
   "source": [
    "pred_lgb, params = train_and_predict_lgbm(cv_X_train, cv_Y_train, cv_X_test, cv_Y_test, cv_X_test)\n",
    "print('Test R-squared for lgb is %f' % r2_score(cv_Y_test, pred_lgb))\n",
    "pred_lgb, _ = train_and_predict_lgbm(X_train, Y_train, None, None, X_test, params=params)\n",
    "\n",
    "get_result_df(pred_lgb, round=True).to_csv('result_lgb_26_features.csv', index=False)\n",
    "# OK Baseline Nice, public and private LB scores are: 1.126919 and 1.127538."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv_fraction = 0.2\n",
    "HP = 50\n",
    "Clip AFTER pred but not after grouping\n",
    "\n",
    "Best score reached: 0.41605717389124625 with params: {'colsample_bytree': 0.55607546409401, 'min_child_samples': 103, 'min_child_weight': 10.0, 'num_leaves': 22, 'reg_alpha': 2, 'reg_lambda': 1, 'subsample': 0.8939112927620336} \n",
    "Test R-squared for lgb is 0.829127\n",
    "\n",
    "<b>================</b>\n",
    "\n",
    "cv_fraction = 0.2\n",
    "HP = 50\n",
    "Clip AFTER pred and after grouping\n",
    "Best score reached: 0.38987888420722855 with params: {'colsample_bytree': 0.8754369812451743, 'min_child_samples': 372, 'min_child_weight': 10.0, 'num_leaves': 44, 'reg_alpha': 1, 'reg_lambda': 0, 'subsample': 0.568664015245299} \n",
    "Test R-squared for lgb is 0.594777\n",
    "\n",
    "\n",
    "<b>================</b>\n",
    "\n",
    "cv_fraction = 0.2\n",
    "HP = 50\n",
    "No clip AFTER pred but not after grouping\n",
    "Best score reached: 0.392851604813763 with params: {'colsample_bytree': 0.9731668400523877, 'min_child_samples': 171, 'min_child_weight': 1e-05, 'num_leaves': 41, 'reg_alpha': 10, 'reg_lambda': 100, 'subsample': 0.5575732396028996} \n",
    "Test R-squared for lgb is 0.678374\n",
    "\n",
    "<b>================</b>\n",
    "Best score reached: 0.5112108383831551 with params: {'colsample_bytree': 0.952164731370897, 'min_child_samples': 111, 'min_child_weight': 0.01, 'num_leaves': 38, 'reg_alpha': 0, 'reg_lambda': 0.1, 'subsample': 0.3029313662262354} \n",
    "Test R-squared for lgb is 0.537906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.79235\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.80813\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.8962\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.84771\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.79324\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.78456\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.89732\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.8291\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.94905\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.98291\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 3.07391\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 3.04218\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.80316\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.81617\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.90088\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.87629\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.79412\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.80039\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.89865\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.84456\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.92478\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.92854\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 3.0206\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.93349\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.77626\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.75562\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.87353\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.81549\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.88872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.89114\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.93081\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.94045\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.8949\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.9005\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.98971\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.90059\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.86161\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.85989\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.94559\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.88765\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid's rmse: 2.77749\n",
      "Best score reached: 0.38987888420722855 with params: {'colsample_bytree': 0.8754369812451743, 'min_child_samples': 372, 'min_child_weight': 10.0, 'num_leaves': 44, 'reg_alpha': 1, 'reg_lambda': 0, 'subsample': 0.568664015245299} \n",
      "Test R-squared for RF is 0.594777\n",
      "Test R-squared for linreg is -1.502108\n",
      "Best alpha: 0.996000; Corresponding r2 score on train: 0.594811\n"
     ]
    }
   ],
   "source": [
    "# pred_tree, params = train_and_predict_tree(cv_X_train, cv_Y_train, cv_X_test)\n",
    "pred_tree, params = train_and_predict_lgbm(cv_X_train, cv_Y_train, cv_X_test, cv_Y_test, cv_X_test)\n",
    "print('Test R-squared for RF is %f' % r2_score(cv_Y_test, pred_tree))\n",
    "\n",
    "pred_lr = train_and_predict_lr(cv_X_train, cv_Y_train, cv_X_test)\n",
    "print('Test R-squared for linreg is %f' % r2_score(cv_Y_test, pred_lr))\n",
    "\n",
    "X_train_level2 = np.c_[pred_tree, pred_lr]\n",
    "\n",
    "best_alpha = get_best_alpha(X_train_level2, cv_Y_test)\n",
    "r2_train_simple_mix = r2_score(cv_Y_test, get_mix(best_alpha, X_train_level2))\n",
    "\n",
    "print('Best alpha: %f; Corresponding r2 score on train: %f' % (best_alpha, r2_train_simple_mix))\n",
    "\n",
    "#### Submision\n",
    "pred_tree, _ = train_and_predict_lgbm(X_train, Y_train, None, None, X_test, params=params)\n",
    "pred_lr = train_and_predict_lr(X_train, Y_train, X_test)\n",
    "\n",
    "X_train_level2 = np.c_[pred_tree, pred_lr]\n",
    "\n",
    "result = get_mix(best_alpha, X_train_level2)\n",
    "\n",
    "get_result_df(result, round=True).to_csv('result_lgb+lr_26_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score reached: 0.5112108383831551 with params: {'colsample_bytree': 0.952164731370897, 'min_child_samples': 111, 'min_child_weight': 0.01, 'num_leaves': 38, 'reg_alpha': 0, 'reg_lambda': 0.1, 'subsample': 0.3029313662262354}\n",
    "\n",
    "Test R-squared for RF is 0.537906\n",
    "\n",
    "Test R-squared for linreg is 0.374154\n",
    "\n",
    "Best alpha: 1.000000; Corresponding r2 score on train: 0.537906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 233\n"
     ]
    }
   ],
   "source": [
    "print('Elapsed: {}'.format(round((time.time()-start))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_result_df(cv_Y_test, round=True).to_csv('result_rfc_26_features_round.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't use old data from year 2013"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
