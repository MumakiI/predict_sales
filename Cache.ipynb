{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prepare historical lags item category\n",
    "if False:    \n",
    "    # Create \"grid\" with columns\n",
    "    index_cols = ['shop_id', 'item_category_id', 'date_block_num']\n",
    "    \n",
    "    sales = pd.merge(df_all, df_items[['item_id', 'item_category_id']], on='item_id', how='left')\n",
    "    \n",
    "    # For every month we create a grid from all shops/items combinations from that month\n",
    "    grid = [] \n",
    "    for block_num in sales['date_block_num'].unique():\n",
    "        cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "        cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_category_id'].unique()\n",
    "        grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "    \n",
    "    # Turn the grid into a dataframe\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "    \n",
    "    # Groupby data to get shop-item_category-month aggregates\n",
    "    gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day': 'shop_item_cat_date_sum'}, inplace=True)\n",
    "    # Join it to the grid\n",
    "    df_all_grouped = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "    \n",
    "    # Groupby data to get shop-month aggregates\n",
    "    gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day': 'shop_date_sum'}, inplace=True)\n",
    "    df_all_grouped = pd.merge(df_all_grouped, gb[['shop_id', 'date_block_num', 'shop_date_sum']], \n",
    "                              how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "    \n",
    "    # Groupby data to get item_category-month aggregates\n",
    "    gb = sales.groupby(['item_category_id', 'date_block_num'], as_index=False).agg({'item_cnt_day':'sum'})\n",
    "    gb.rename(columns={'item_cnt_day': 'item_cat_date_sum'}, inplace=True)\n",
    "    df_all_grouped = pd.merge(df_all_grouped, gb[['item_category_id', 'date_block_num', 'item_cat_date_sum']], \n",
    "                              how='left', on=['item_category_id', 'date_block_num']).fillna(0)\n",
    "    \n",
    "    # TODO create item_cnt_day_by_item_cat weighted by items count in group\n",
    "    \n",
    "    \n",
    "    # List of columns that we will use to create lags\n",
    "    cols_to_rename = list(df_all_grouped.columns.difference(index_cols)) \n",
    "    \n",
    "    shift_range = [1, 2, 3, 4, 5, 12]\n",
    "    \n",
    "    for month_shift in tqdm.tqdm(shift_range):\n",
    "        train_shift = df_all_grouped[index_cols + cols_to_rename].copy()\n",
    "        \n",
    "        train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "        \n",
    "        foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "        train_shift = train_shift.rename(columns=foo)\n",
    "    \n",
    "        df_all_grouped = pd.merge(df_all_grouped, train_shift, on=index_cols, how='left').fillna(0)\n",
    "    \n",
    "    # we may have only historical data for target month, we don't know aggregations for it, hence deleting\n",
    "    df_all_grouped.drop(columns=['shop_item_cat_date_sum', 'item_cat_date_sum', 'shop_date_sum'], inplace=True)\n",
    "    \n",
    "    # merge history back to train/test set \n",
    "    df_all_gr_by_item_cat = pd.merge(sales, df_all_grouped, on=index_cols, how='left').fillna(0)\n",
    "    df_all_gr_by_item_cat.drop(columns=['date', 'item_price', 'item_id', 'item_cnt_day'], inplace=True)\n",
    "    df_all_gr_by_item_cat = downcast_dtypes(df_all_gr_by_item_cat)\n",
    "    \n",
    "    del grid, df_all_grouped, sales, train_shift\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': [0.55, 0.65, 0.75, 0.85, 0.95],\n",
    "               'metric': ['rmse'],\n",
    "               'nthread':[-1], \n",
    "               'min_data_in_leaf': [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10], \n",
    "               'bagging_fraction': [0.65, 0.75, 0.85], \n",
    "               'learning_rate': [0.1, 0.01, 0.03], \n",
    "               'objective': ['mse'], \n",
    "               'bagging_seed': [2**7], \n",
    "               'num_leaves': sp_randint(100, 1000),\n",
    "               'bagging_freq':[1],\n",
    "               'verbose':[0] \n",
    "              }\n",
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'mse', \n",
    "            \"eval_set\" : [(cv_X_test, cv_Y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}\n",
    "\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "clf = lgb.LGBMRegressor(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=10)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=lgb_params, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='r2',\n",
    "    cv=4,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=False)\n",
    "gs.fit(cv_X_train, cv_Y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.95,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 16, \n",
    "               'bagging_fraction': 0.85, \n",
    "               'learning_rate': 0.1, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 906,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=Y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "get_result_df(pred_lgb).to_csv('result_lgb_26_features.csv', index=False)\n",
    "# print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))\n",
    "# Your solution can be improved by a lot! Your public and private LB scores are: 1.319619 and 1.318699."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
